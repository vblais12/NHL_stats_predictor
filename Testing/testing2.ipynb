{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('newdata.csv', index_col=0)\n",
    "data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def rolling_averages(team, cols, new_cols, window=3):\n",
    "    team = team.sort_values(\"Date\")    # Getting team data organized chronologically\n",
    "    rolling = team[cols].rolling(window, closed='left').mean()   # closed=left to ignore current row in sliding window\n",
    "    team[new_cols] = rolling\n",
    "    team = team.dropna(subset=new_cols) # dropping first rows because not enough data\n",
    "    return team\n"
   ],
   "id": "75798beac165dea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_opp = data.drop(columns=['Opponent']).rename(columns={\n",
    "    'Team': 'Opponent',\n",
    "    'CF': 'Opponent_CF',\n",
    "    'CA': 'Opponent_CA',\n",
    "    'CF%': 'Opponent_CF%',\n",
    "    'FF': 'Opponent_FF',\n",
    "    'FA': 'Opponent_FA',\n",
    "    'FF%': 'Opponent_FF%',\n",
    "    'SF': 'Opponent_SF',\n",
    "    'SA': 'Opponent_SA',\n",
    "    'GF': 'Opponent_GF',\n",
    "    'GA': 'Opponent_GA',\n",
    "    'xGF': 'Opponent_xGF',\n",
    "    'xGA': 'Opponent_xGA',\n",
    "    'xGF%': 'Opponent_xGF%',\n",
    "    'HDCF' : 'Opponent_HDCF',\n",
    "    'HDCF%' : 'Opponent_HDCF%',\n",
    "    'SCF' : 'Opponent_SCF',\n",
    "    'PDO' : 'Opponent_PDO'\n",
    "})\n",
    "\n",
    "\n",
    "merged = data.merge(\n",
    "    data_opp,\n",
    "    left_on=['Date', 'Opponent'],\n",
    "    right_on=['Date', 'Opponent'],\n",
    "    suffixes=('', '_y')  # Avoids conflicts if any columns aren’t renamed\n",
    ")"
   ],
   "id": "250915d678cac86c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "merged = data.merge(\n",
    "    data_opp,\n",
    "    left_on=['Date', 'Opponent'],\n",
    "    right_on=['Date', 'Opponent'],\n",
    "    suffixes=('', '_y')  # Avoids conflicts if any columns aren’t renamed\n",
    ")"
   ],
   "id": "603f87bc0fddef68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "merged",
   "id": "8377c07a2f572be9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "merged['CF_diff'] = merged['CF'] - merged['Opponent_CF']\n",
    "merged['CF%_diff'] = merged['CF%'] - merged['Opponent_CF%']\n",
    "merged['GF_diff'] = merged['GF'] - merged['Opponent_GF']\n",
    "merged['xGF_diff'] = merged['xGF'] - merged['Opponent_xGF']\n",
    "merged['HDCF_diff'] = merged['HDCF'] - merged['Opponent_HDCF']\n",
    "merged['HDCF%_diff'] = merged['HDCF%'] - merged['Opponent_HDCF%']\n",
    "merged['FF_diff'] = merged['FF'] - merged['Opponent_FF']\n",
    "merged['FF%_diff'] = merged['FF%'] - merged['Opponent_FF%']\n",
    "merged['SCF_diff'] = merged['SCF'] - merged['Opponent_SCF']\n",
    "merged['PDO_diff'] = merged['PDO'] - merged['Opponent_PDO']\n"
   ],
   "id": "a2bd8f1bf005785f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "merged",
   "id": "7655350b606f9410",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "merged['GF%'] = pd.to_numeric(merged['GF%'], errors='coerce')\n",
    "merged['xGF%'] = pd.to_numeric(merged['xGF%'], errors='coerce')\n",
    "\n",
    "print(merged[['GF%', 'xGF%']].dtypes)"
   ],
   "id": "c79114c7751b8c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictors = [\n",
    "    'CF%', 'FF%', 'SF%', 'xGF%', 'SCF%', 'HDCF%', 'GF%', 'SH%', 'SV%', 'HDCA', 'xGA', 'PDO'\n",
    "]\n",
    "predictors += ['CF', 'CA', 'FF', 'FA', 'SF', 'GA', 'GF', 'SCA', 'SCF', 'HDCF']\n",
    "predictors_diff = ['CF_diff', 'CF%_diff', 'GF_diff', 'xGF_diff', 'HDCF_diff', 'HDCF%_diff', 'FF_diff', 'FF%_diff', 'SCF_diff', 'PDO_diff']\n",
    "\n",
    "all_predictors = predictors + predictors_diff\n",
    "\n",
    "#all_predictors = ['CF%', 'SF%', 'xGF%', 'SV%']\n",
    "\n",
    "new_cols = [f'{c}_rolling' for c in all_predictors]\n",
    "\n",
    "predictors = all_predictors\n",
    "\n"
   ],
   "id": "f4d7865b73ffc061",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(merged[predictors].dtypes)",
   "id": "cd6b1f15ad1502b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "merged['xGF%'] = pd.to_numeric(merged['xGF%'], errors='coerce')\n",
    "merged['GF%'] = pd.to_numeric(merged['GF%'], errors='coerce')\n",
    "print(merged[predictors].dtypes)"
   ],
   "id": "1d3f757d074f01f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = merged.groupby('Team').apply(lambda x: rolling_averages(x, predictors, new_cols, 3))\n",
    "data = data.droplevel('Team')\n",
    "data.index = range(data.shape[0])\n",
    "data"
   ],
   "id": "2a8bf03bafef34d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.drop(columns=['Result_y'], inplace=True)",
   "id": "77d527a2f1e38b69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cols = list(data.columns)\n",
    "# Remove 'Date' from the list\n",
    "cols.remove('Date')\n",
    "cols.remove('Result')\n",
    "# Insert 'Date' as the second column (index 1)\n",
    "cols.insert(1, 'Date')\n",
    "cols.insert(2, 'Result')\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "data = data[cols]"
   ],
   "id": "3b596ded8c07224a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data",
   "id": "16e77be83af4c00e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#####\n",
    "# 1. Initialize Elo ratings\n",
    "initial_elo = 1500\n",
    "teams = data['Team'].unique()\n",
    "elo_ratings = {team: initial_elo for team in teams}\n",
    "\n",
    "elo_features = []\n",
    "\n",
    "# 2. Loop through each game and update ratings\n",
    "for idx, row in data.iterrows():\n",
    "    team = row['Team']\n",
    "    opponent = row['Opponent']\n",
    "    venue = row['venue']\n",
    "    result = row['Result']  # 1 if win, 0 if loss\n",
    "\n",
    "    # Optional: home-ice advantage\n",
    "    team_elo = elo_ratings[team] + (35 if venue == 'Home' else 0)\n",
    "    opponent_elo = elo_ratings[opponent]\n",
    "\n",
    "    # Store Elo features BEFORE the game\n",
    "    elo_features.append({\n",
    "        'team_elo': team_elo,\n",
    "        'opponent_elo': opponent_elo,\n",
    "        'elo_diff': team_elo - opponent_elo\n",
    "    })\n",
    "\n",
    "    # Calculate expected outcome\n",
    "    expected_win = 1 / (1 + 10 ** ((opponent_elo - team_elo) / 400))\n",
    "\n",
    "    # Elo update (K-factor can be tuned)\n",
    "    k = 30\n",
    "    change = k * (result - expected_win)\n",
    "    elo_ratings[team] += change\n",
    "    elo_ratings[opponent] -= change\n",
    "\n",
    "# Convert Elo features to DataFrame\n",
    "elo_df = pd.DataFrame(elo_features)\n",
    "\n",
    "# Merge with combined_team_view\n",
    "games_data = pd.concat([data.reset_index(drop=True), elo_df], axis=1)\n",
    "\n",
    "####\n",
    "new = ['team_elo', 'opponent_elo', 'elo_diff']\n",
    "predictors = predictors + new"
   ],
   "id": "3ca7ff69b1f87d25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = XGBClassifier(random_state=10, )  # base model\n",
    "\n",
    "# Defining Time Series Split\n",
    "TSS = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "test_model = RandomForestClassifier(random_state=10)\n",
    "\n",
    "lin = BaggingClassifier(LogisticRegression(random_state=10, solver='liblinear', penalty='l2', max_iter=1000))\n"
   ],
   "id": "4ab684c4853b82d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Function to make predictions given the data, input features and chosen model\n",
    "\n",
    "def make_predictions(data, predictors, model):\n",
    "    train = data[data['Date'] < '2024-04-19']\n",
    "    #train = train[train['Date'] > '2022-10-06']\n",
    "    test = data[data['Date'] > '2024-04-19']\n",
    "    model.fit(train[predictors], train['Result'])\n",
    "    preds = model.predict(test[predictors])\n",
    "    combined  = pd.DataFrame(dict(actual=test['Result'], prediction = preds), index=test.index)\n",
    "    precision = precision_score(test['Result'], preds)\n",
    "    return combined, precision"
   ],
   "id": "174d61473d2d4f06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Defining search space for GridSearchCV\n",
    "search_grid = {\n",
    "    'n_estimators': [50, 75, 100, 150],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.02, 0.03],\n",
    "    'reg_alpha': [1, 5, 10],\n",
    "    'reg_lambda': [1, 5, 10]\n",
    "\n",
    "}\n",
    "\n",
    "alt_search_grid = {\n",
    "    'n_estimators' : [50, 100, 200],\n",
    "    'max_depth' : [3, 6, 9],\n",
    "    'min_samples_split': [3, 5, 10]\n",
    "}\n",
    "\n",
    "lin_search_grid = {\n",
    "    # Logistic Regression hyperparameters (base_estimator__)\n",
    "    'estimator__C' : [0.5, 0.8, 1.0],\n",
    "    'n_estimators': [10, 50, 100, 150, 200],\n",
    "}\n",
    "\n",
    "GS = GridSearchCV(\n",
    "    estimator = model,\n",
    "    param_grid = search_grid,\n",
    "    scoring = 'neg_log_loss',\n",
    "    refit = True,\n",
    "    cv = TSS,\n",
    "    verbose= 4\n",
    ")\n",
    "\n",
    "training = data[data['Date'] < '2024-04-19']  # Training using 2021-2024 data\n",
    "#training = training[training['Date'] > '2022-10-06']\n",
    "testing = data[data['Date'] > '2024-04-19']   # Testing on most recent season (2024-2025)\n",
    "print(training.columns[training.columns.str.contains('Result')])"
   ],
   "id": "b808d390b9aaf50d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predictors",
   "id": "1180db15e1320382",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(type(training['Result']))         # should be <class 'pandas.Series'>\n",
    "print(training['Result'].shape)        # should be (n_samples,)"
   ],
   "id": "db5b763d982fac4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "GS.fit(training[predictors], training['Result'])     # Training",
   "id": "6e48637756a103db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "GS.best_score_",
   "id": "b5789ab2ed51efff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "new_model = GS.best_estimator_\n",
    "new_model"
   ],
   "id": "90a2716f2fbdedd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined, precision = make_predictions(data, new_cols, new_model)\n",
    "precision"
   ],
   "id": "9b35bfeea0977fe7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, log_loss\n",
    "\n",
    "predictions = new_model.predict(testing[new_cols])\n",
    "\n",
    "print(classification_report(testing['Result'], predictions))"
   ],
   "id": "f260ceb86803bcfe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create DataFrame pairing features with their importances\n",
    "importances = pd.DataFrame({\n",
    "    'Feature': new_cols,\n",
    "    'Importance': new_model.feature_importances_\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top features\n",
    "print(importances.head(10))"
   ],
   "id": "13fa575dc0d72118",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(data['Result'].unique())\n",
    "print(training['Result'].value_counts())"
   ],
   "id": "9ac962499d0517a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(training[new_cols].info())\n",
    "print(training[new_cols].isna().sum())\n",
    "print(training[new_cols].describe())\n"
   ],
   "id": "df8367b348020219",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# Check class balance after preprocessing\n",
    "print(data['Result'].value_counts())\n",
    "\n",
    "# Check if model predicted any 1s\n",
    "print(np.unique(predictions, return_counts=True))\n",
    "\n",
    "# Look at rolling feature distribution\n",
    "print(training[new_cols].describe())"
   ],
   "id": "e8ff0c7197234fd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dbbbda321fee2c19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ab588f1229e93933",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
