{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('games.csv', index_col=0)"
   ],
   "id": "ba450b23ba1c1e8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cleaning / getting data ready for machine learning\n",
    "data['venue'] = data['venue'].map({'Home' : 1, 'Away' : 0})     # convert venue to 1's and 0's\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['opponent'] = data['Opponent'].astype('category').cat.codes # Converting opponent to integers\n",
    "data = data.drop(columns=['Time'], inplace=False)                # Dropping time column\n",
    "data = data[data[\"Team\"] != \"Arizona Coyotes\"]                   # Team doesnt exist anymore\n",
    "\n",
    "predict = ['venue']"
   ],
   "id": "b92b2e0cc2998287",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data",
   "id": "592562bc02b560c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to compute rolling averages over the last 3 games. Games for which there isnt enough data (i.e. the first 3 games of each teams) are dropped\n",
    "\n",
    "def rolling_averages(team, cols, new_cols, window=3):\n",
    "    team = team.sort_values(\"Date\")    # Getting team data organized chronologically\n",
    "    rolling = team[cols].rolling(window, closed='left').mean()   # closed=left to ignore current row in sliding window\n",
    "    team[new_cols] = rolling\n",
    "    team = team.dropna(subset=new_cols) # dropping first rows because not enough data\n",
    "    return team"
   ],
   "id": "398ca61304f012c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cols = ['G', 'GA', 'S', 'SV%', 'S%']   # wanted columns for rolling\n",
    "new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "predictors = new_cols + predict                         # New predictors\n",
    "\n",
    "\n",
    "games_data = data.groupby('Team').apply(lambda x: rolling_averages(x, cols, new_cols, 3))   # Compute rolling averages\n",
    "games_data = games_data.droplevel(\"Team\")\n",
    "games_data.index = range(games_data.shape[0])  # fixing index level\n",
    "games_data"
   ],
   "id": "44cee83d85cb0206",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "games_data = games_data[\n",
    "        (games_data['Team'] != 'Arizona Coyotes') &\n",
    "        (games_data['Opponent'] != 'Arizona Coyotes')\n",
    "        ]"
   ],
   "id": "f8e6b31bde6a6b3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#####\n",
    "# 1. Initialize Elo ratings\n",
    "initial_elo = 1500\n",
    "teams = games_data['Team'].unique()\n",
    "elo_ratings = {team: initial_elo for team in teams}\n",
    "\n",
    "elo_features = []\n",
    "\n",
    "# 2. Loop through each game and update ratings\n",
    "for idx, row in games_data.iterrows():\n",
    "    team = row['Team']\n",
    "    opponent = row['Opponent']\n",
    "    venue = row['venue']\n",
    "    result = row['Result']  # 1 if win, 0 if loss\n",
    "\n",
    "    # Optional: home-ice advantage\n",
    "    team_elo = elo_ratings[team] + (35 if venue == 'Home' else 0)\n",
    "    opponent_elo = elo_ratings[opponent]\n",
    "\n",
    "    # Store Elo features BEFORE the game\n",
    "    elo_features.append({\n",
    "        'team_elo': team_elo,\n",
    "        'opponent_elo': opponent_elo,\n",
    "        'elo_diff': team_elo - opponent_elo\n",
    "    })\n",
    "\n",
    "    # Calculate expected outcome\n",
    "    expected_win = 1 / (1 + 10 ** ((opponent_elo - team_elo) / 400))\n",
    "\n",
    "    # Elo update (K-factor can be tuned)\n",
    "    k = 30\n",
    "    change = k * (result - expected_win)\n",
    "    elo_ratings[team] += change\n",
    "    elo_ratings[opponent] -= change\n",
    "\n",
    "# Convert Elo features to DataFrame\n",
    "elo_df = pd.DataFrame(elo_features)\n",
    "\n",
    "# Merge with combined_team_view\n",
    "games_data = pd.concat([games_data.reset_index(drop=True), elo_df], axis=1)\n",
    "\n",
    "####\n",
    "new = ['team_elo', 'opponent_elo', 'elo_diff']\n",
    "predictors = predictors + new"
   ],
   "id": "7a303ab8a58c39ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "games_data",
   "id": "cc178df7e6ec4454",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "games_data['days_since_last'] = games_data.groupby('Team')['Date'].diff().dt.days\n",
    "games_data['days_since_last'].fillna(-1, inplace=True)\n",
    "\n",
    "games_data['goal_diff'] = games_data['G'] - games_data['GA']\n",
    "\n",
    "test = ['goal_diff']\n",
    "new_col = ['goal_diff_rolling']\n",
    "\n",
    "games_data = games_data.groupby('Team').apply(lambda x: rolling_averages(x, test, new_col, 5))\n",
    "games_data = games_data.droplevel('Team')\n",
    "games_data.index = range(len(games_data))\n",
    "\n",
    "games_data"
   ],
   "id": "1349c917c513cab5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "new_pred = ['days_since_last']\n",
    "predictors = predictors + new_pred\n",
    "predictors"
   ],
   "id": "adc37679796111bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = XGBClassifier(random_state=10, )    # base model\n",
    "\n",
    "# Defining Time Series Split\n",
    "TSS = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "test_model = RandomForestClassifier(random_state=10)\n",
    "\n",
    "lin = BaggingClassifier(LogisticRegression(random_state=10, solver='liblinear', penalty='l2', max_iter = 1000))\n"
   ],
   "id": "1a9c2e354e4c29c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Function to make predictions given the data, input features and chosen model\n",
    "\n",
    "def make_predictions(data, predictors, model):\n",
    "    train = data[data['Date'] < '2024-04-19']\n",
    "    #train = train[train['Date'] > '2022-10-06']\n",
    "    test = data[data['Date'] > '2024-04-19']\n",
    "    model.fit(train[predictors], train['Result'])\n",
    "    preds = model.predict(test[predictors])\n",
    "    combined  = pd.DataFrame(dict(actual=test['Result'], prediction = preds), index=test.index)\n",
    "    precision = precision_score(test['Result'], preds)\n",
    "    return combined, precision"
   ],
   "id": "9aba6ef5e8c7d0f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Defining search space for GridSearchCV\n",
    "search_grid = {\n",
    "    'n_estimators': [50, 75, 100, 150],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.02, 0.03],\n",
    "    'reg_alpha': [1, 5, 10],\n",
    "    'reg_lambda': [1, 5, 10]\n",
    "\n",
    "}\n",
    "\n",
    "alt_search_grid = {\n",
    "    'n_estimators' : [50, 100, 200],\n",
    "    'max_depth' : [3, 6, 9],\n",
    "    'min_samples_split': [3, 5, 10]\n",
    "}\n",
    "\n",
    "lin_search_grid = {\n",
    "    # Logistic Regression hyperparameters (base_estimator__)\n",
    "    'estimator__C' : [0.5, 0.8, 1.0],\n",
    "    'n_estimators': [10, 50, 100, 150, 200],\n",
    "}\n",
    "\n",
    "GS = GridSearchCV(\n",
    "    estimator = test_model,\n",
    "    param_grid = alt_search_grid,\n",
    "    scoring = 'neg_log_loss',\n",
    "    refit = True,\n",
    "    cv = TSS,\n",
    "    verbose= 4\n",
    ")\n",
    "\n",
    "training = games_data[games_data['Date'] < '2024-04-19']  # Training using 2021-2024 data\n",
    "#training = training[training['Date'] > '2022-10-06']\n",
    "testing = games_data[games_data['Date'] > '2024-04-19']   # Testing on most recent season (2024-2025)\n"
   ],
   "id": "1d83f750acc4af36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "GS.fit(training[predictors], training['Result'])     # Training",
   "id": "7d03aa1d02156ea1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "GS.best_score_",
   "id": "c71469c770969e9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "new_model = GS.best_estimator_\n",
    "new_model"
   ],
   "id": "eb609dfe16a1288",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined, precision = make_predictions(games_data, predictors, new_model)\n",
    "precision"
   ],
   "id": "6712b1943920c9cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, log_loss\n",
    "predictions = new_model.predict(testing[predictors])\n",
    "\n",
    "print(classification_report(testing['Result'], predictions))"
   ],
   "id": "8401f9d896add79d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create DataFrame pairing features with their importances\n",
    "importances = pd.DataFrame({\n",
    "    'Feature': predictors,\n",
    "    'Importance': new_model.feature_importances_\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top features\n",
    "print(importances.head(10))\n"
   ],
   "id": "6b4ead503e5262f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined",
   "id": "27e450e13467999a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined = combined.merge(games_data[['Date', 'Team', 'Opponent', 'Result']], left_index=True, right_index=True)\n",
    "combined"
   ],
   "id": "d2328728a9455801",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "final = combined.merge(combined, left_on=['Date', 'Team'], right_on=['Date', 'Opponent'])  # few games will drop due to rolling windows\n",
    "final"
   ],
   "id": "8341fc2d42d05d67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final[(final['prediction_x'] == 1) & (final['prediction_y'] == 0)]['actual_x'].value_counts()",
   "id": "89afc5d0e580d64d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final[(final['prediction_x'] == 0) & (final['prediction_y'] == 1)]['actual_y'].value_counts()",
   "id": "a5fe73601e590ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Overall accuracy turned out to be ~60%.\")\n",
    "print(\"However, when merging predictions for both games, we can see that the model is 63.3% accurate when both teams predictions match.\")"
   ],
   "id": "1f60d5620a374cda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total = 560 + 390\n",
    "total"
   ],
   "id": "fb67fc3dc42ebf25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "560/total",
   "id": "55b346e3bb94dddc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7fe60639bfe6b1bb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
